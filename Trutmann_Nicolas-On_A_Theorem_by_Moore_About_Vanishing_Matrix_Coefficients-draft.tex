% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{mathrsfs}
\newtheorem{defn}{Definition}
\usepackage{biblatex}
\addbibresource{refs.bib}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={On Theorem by Moore about Vanishing Matrix Coefficients},
  pdfauthor={Nicolas Trutmann},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{On Theorem by Moore about Vanishing Matrix Coefficients}
\author{Nicolas Trutmann}
\date{}

\begin{document}
\maketitle

In this paper we'll showcase a theorem in ergodic theory by Howe and
Moore \cite{howe79}. On the way there, we'll touch many different
fields, from measure theory, over functional analysis, representation
theory and ergodic theory of course.

This paper is based on the book ``Ergodic Theory and semisimple Lie
Groups'' by Robert Zimmer \cite{Zimmer84}, in particular the first two
chapters, which contain the theorem itself (Theorem 2.2.20) and
surrounding material concerning ergodic theory.

{[}{[}todo{]}{]} (this is uglily wrenched in here. find more elegant
place for this) The main aim of the book by Zimmer is focused on two
theorems by Mostow and Margulis. The ``arithmeticity theorem'' and the
``rigidity theorem'', which show how Lie groups and lattices in them
interact.

The techniques of the proof show a nice interplay between fields and
their different approaches, while staying relatively simple. We assume
the reader to have an undergraduate level understanding of the
prerequisites in algebra and representation theory, but will state
foundational information regardless, and provide references in all
cases. We furthermore take care to clarify notation before use.

The theorem, which we will state shortly, is historically at home in the
development of ergodic theory, which in turn is a relatively new field
of mathematics. The original definition of ergodicity was given in 1928
in a paper by P. Smith and G. Birkhoff on dynamical systems. The concept
gained importance in 1931 when von Neumann and Birkhoff nearly
simultaneously proved the mean and pointwise ergodic theorems. These may
be regarded as the starting point of the subject.

{[}{[}todo{]}{]} (find these: Margulis, Borel, Furstenberg, Kazhdan,
Moore, Howe, and Zimmer \cite{Mackey74}) The paper by Moore
\cite{Moore66} was published in 1966. Margulis' Theorems were published
in {[}{[}todo{]}{]} (wtf, idk. historical research has never been my
forte) Initially for dynamical systems, with physics applications, here
however actions of more general groups are studied with respect to
ergodicity.

Sources for the historical background: \cite{Mackey74}(chapter 1.
Introduction) \cite{Zimmer84}(chapter 1. Introduction)

The theorem itself does not directly involve ergodicity, but is instead
used to prove ergodicity.

The theorem itself is rather simple to state:

{[}{[}Moore's Ergodicity Theorem{]}{]}

To clarify some points, note that we have specified non-compact groups.
This allows us to talk about ``infinity'' at all. Next, what is an
invariant vector? Simply, for all \(g\in G\), and a vector \(v\), we
have that \(\pi(g)v = v\), or, that \(v\) is preserved by any linear map
given by the representation.

\hypertarget{introduction}{%
\subsection{Introduction}\label{introduction}}

{[}{[}todo{]}{]} (remove this section once implemented) - historical
context -\textgreater{} up in first section. maybe move down - where
this theorem comes from -\textgreater{} \cite{howe79} - what it does -
why we care - how we're gonna go about it

\hypertarget{question-when-is-an-action-ergodic}{%
\subsection{question: when is an action
ergodic?}\label{question-when-is-an-action-ergodic}}

Instead of verifying ergodicity for any given action, space and measure
individually, can we find criteria for ergodicity that are easier to
evaluate? The Moore's theorem sits in the middle of an argument that
answers the following question.

Let \(G\) be a semisimple Lie group and \(S\) an ergodic \(G\)-space. If
\(H\subset G\) is a closed subgroup, when is \(H\) ergodic on \(S\).

{[}{[}todo{]}{]} (fill out) Why would we care? -\textgreater{} boundary
action, lattices in ss groups, asymptotic behavior in non-compact groups
\cite{howe79}
Now that we have a concrete question, let us try to get our hands dirty
on an example. We'll use the action of fractional linear transforms on
the upper half plane, which is nice, because we can look at hyperbolic
geometry and draw meaningful pictures of the maps and spaces involved.
It'll bring intuition about the question and why one would care to
answer the question.

I get the first map now. The action, let's name it for now,
\(\alpha : SL(2, \mathbb{R}) \curvearrowright \mathbb{H} \rightarrow \mathbb{H}\),
wich acts by fractional linear transform. \#\# Lemma 1.
\(K:= SO(2, \mathbb{R})\) is the stabilizer of \(i \in \mathbb{H}\). 2.
therefore, \(G/K \cong AN\) with \(KAN \cong G\) being the Iwasawa
decomp.

\hypertarget{proof}{%
\subsubsection{proof}\label{proof}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  from \cite{Miyake89}(Theorem 1.1.3) map to Klein disk; use Schwarz
  lemma; map back.
\end{enumerate}

How does the second map work? Using the same fractional linear transform
but we take a real value instead of a complex one. It is easy to
visualize as a regular matrix product with
\(\begin{pmatrix}x \\ 1\end{pmatrix}\) and projecting it to the
projective line. \[
\begin{pmatrix}a & b \\ c & d\end{pmatrix}\begin{pmatrix}x \\ 1\end{pmatrix} =
\begin{pmatrix}ax + b \\ cx + d\end{pmatrix} \quad \rightarrow \quad
\begin{pmatrix}\frac{ax + b}{cx + d} \\ 1\end{pmatrix}
\] {[}{[}create images for{]}{]}: the one I've already made for this on
the other pc.

next we care about the behavior of a lattice \(\Gamma \subset G\). If
\(G\) acts transitively on a space \(X\), then there is an isomorphism
of \(G\)-spaces \(G/G_x \rightarrow X\), where \(G_x = Stab_G (x)\) for
\(x \in X\), given by the map \(gG_x \mapsto gx\). In the case of our
example \(G = SL(2, \mathbb{R})\), and, as we've shown in the preceding
lemma, we know the stabilizer of \(i\) to be \(SO(2,\mathbb{R})\). \#\#
where we want to go We want to show that the action of \(\Gamma\) on
\(\bar{\mathbb{R}}\) is ergodic

\hypertarget{from-book}{%
\subsection{from book}\label{from-book}}

\href{Zimmer\%20p.4}{{[}unoriginal{]}} To see why ergodicity is
relevant, and in fact to say a word about what it is, let us consider a
classical example. Let \(G = SL(2, \mathbb{R})\), and let \(X\) be the
upper half plane, \(X= \{z \in \mathbb{C} | lm(z) > 0\}\). As is well
known\href{upper\%20half\%20plane,\%20m√∂bius\%20transforms,\%20give\%20reference\%20to\%20misc\%20things.\%20and\%20figure\%20out\%20what\%20the\%20actual\%20example\%20is.\%20figure\%20out\%20what\%20the\%20theorem\%20tries\%20to\%20answer.}{{[}todo{]}},
G acts on X via fractional linear transformations, i.e., \[
g \cdot z=\frac{(az+b)}{(cz+d)}
\quad
\text{ where }g=
\begin{pmatrix}a & b \\ c & d\end{pmatrix}
\] Suppose now that \(\Gamma \subset G\) is a lattice, which we assume
to be torsion free for simplicity. Since the action of \(G\) on \(X\)
allows an identification of \(X\) with \(G/K\), where \(K = SO(2)\) (the
stabilizer of \(i \in X\)), and \(K\) is compact, it follows that the
action of \(\Gamma\) on \(X\) is properly discontinuous, and so
\(\Gamma\backslash X\) will be a manifold, in fact a finite volume
Riemann surface. On the other hand, via the same fractional linear
formula, \(G\) acts on
\(\bar{\mathbb{R}} = \mathbb{R} \cup \{ \infty \}\), and
\(\bar{\mathbb{R}}\) can be identified with \(G/P\), where \(P\) is the
group of upper triangular matrices and the stabilizer of
\(\infty \in \bar{\mathbb{R}}\). Once again, we can consider the action
of \(\Gamma\) on \(\bar{\mathbb{R}}\), but now the action will be very
far from being properly discontinuous. In fact, every \(\Gamma\)-orbit
in \(\bar{\mathbb{R}}\) will be a (countable) dense set. In particular,
if we try taking the quotient \(\Gamma\backslash\bar{\mathbb{R}}\), we
obtain a space with the trivial topology. On the other hand,
\(\bar{\mathbb{R}}\) provides a natural compactification of \(X\), and
in fact \(\bar{\mathbb{R}}\) can be identified with asymptotic
equivalence classes of geodesics in \(X\), where \(X\) has the
essentially unique \(G\)-invariant metric. Thus, it is certainly
reasonable to expect the action of \(\Gamma\) on \(\bar{\mathbb{R}}\) to
yield useful information. However, a thorough understanding requires us
to come to grips with actions in which the orbits are very complicated
(e.g.~dense) sets. Ergodic theory is (in large part) the study of
complicated orbit structure in the presence of a measure. Not only are
there no non-constant \(\Gamma\)-invariant continuous real-valued
functions on \(\bar{\mathbb{R}}\), but the same is true for measurable
functions. This is embodied in the following definition.

\hypertarget{definition}{%
\subsection{Definition}\label{definition}}

Suppose \(G\) acts on a measure space \((S, \mu)\) so that the action
map \(S \times G \rightarrow S\) is measurable and \(\mu\) is
quasi-invariant, i.e., \(\mu(A) = 0\) if and only if \(\mu(Ag) = 0\).
The action is called ergodic if \(A \subset S\) is measurable and
\(G\)-invariant implies \(\mu(A) = 0\) or \(\mu(S\setminus A) = 0\).
Now that we have stated the goal of the paper, let us immediately make a
detour. We will state definitions and relevant theorems (without proof)
in compact form with ample references so that a reader can catch up if
necessary. The advanced reader can skip this section and move straight
to the next topic without issue.

\href{ergodicity}{{[}todo{]}} (put references for everything in each
section)

Throughout the whole text, unless otherwise stated, G is a countable
discrete group. Its identity element will always be denoted by e.

\hypertarget{measure-spaces}{%
\section{Measure Spaces}\label{measure-spaces}}

A \emph{measurable space} is a pair \((X, \mathscr{B})\) where \(X\) is
a set and \(\mathscr{B}\) is a \(\sigma\)-algebra of subsets of \(X\).
Elements of \(\mathscr{B}\) are called \emph{measurable sets}. A
function of measurable spaces \(f: X \rightarrow Y\) is called
\emph{measurable} if \(f^{-1}(A)\) is a measurable set in \(X\) for all
measurable sets \(A\) of \(Y\).

A \emph{measure} on a measurable space \((X, \mathscr{B})\) is a map
\(\mu: \mathscr{B} \rightarrow [0, \infty]\) such that -
\(\mu(\emptyset) = 0\), and -
\(\mu(\cup_{n=1}^{\infty} A_n) = \sum_{n=1}^{\infty} \mu(A_n)\) for
every countable collection \(\{A_n\}_{n=1}^{\infty}\) of pairwise
disjoint sets in \(\mathscr{B}\) (countable additivity).

The Borel \(\sigma\)-algebra of a topological space \(X\) is the
\(\sigma\)-algebra \(\mathscr{B}\) generated by the open subsets of
\(X\) , and the members of \(\mathscr{B}\) are called Borel sets (we may
also refer to them as measurable sets if we are viewing
\((X, \mathscr{B})\) abstractly as a measurable space). A Borel measure
on \(X\) is a probability measure on the Borel \(\sigma\)-algebra of
\(X\).

\hypertarget{representations}{%
\subsection{Representations}\label{representations}}

The notation(s) in representation theory are sometimes confusing, so
here we clarify which words we will use to mean which objects. We will
revisit representations in detail in the following chapter, so we will
be brief.

\begin{defn}
A representation is a group-homomorphism from a group into the general linear group of a vector space.
$$
\pi: G \rightarrow GL(V)
$$
\end{defn}

We consistently use lowercase Greek letters to refer to representations.
Most often \(\pi\) and \(\lambda\).

The vector space \(V\) is often not just a vector space but a
topological vector space and in particular a Hilbert space.

\href{ergodicity}{{[}todo{]}} (all of this) repr: a map dim of a repr
agree with topology. unitary repr. A unitary representation

\hypertarget{direct-difference-notation}{%
\subsection{``direct difference''
notation}\label{direct-difference-notation}}

Zimmer, and we, use the symbol ``\(\ominus\)'' to denote ``subtraction''
of linear subspaces of Hilbert spaces. If \(A \subset B\) are linear
subspaces of a Hilbert space,
\(B \ominus A = \{x \in B: (x,y) = 0 \text{ for all }y \in A\}\). \#\#
Group Actions By an action of the group \(G\) on a set \(X\) we mean a
map \(\alpha: G \times X \rightarrow X\) such that, writing the first
argument as a subscript, \(\alpha_s(\alpha_t(x)) = \alpha_{st}(x)\) and
\(\alpha_e(x) = x\) for all \(x \in X\) and \(s, t \in G\). Most of the
time we will not give this map a name and write the image of a pair
\((s, x)\) written as \(sx\), or as \(s \cdot x\) if there is a chance
of notational confusion. For sets \(A \subset X\) and \(K \subset G\)
and an \(s \in G\) we write \[
s A = \{sx : x \in A\},
\quad
K x = \{sx : s \in K \},
\quad
K A = \{sx : x \in A \text{ and } s \in K \}.
\] The \emph{G-orbit} of a point \(x \in X\) is the set \(Gx\).

\begin{defn}{quasi-invariant}
A measure $\mu$ is quasi-invariant under a group action of $G$ if it preserves null sets.
If $A = gA$ then either $\mu(A)=0$ or $\mu(S\setminus A)=0$.
\end{defn}

\hypertarget{ergodicity}{%
\subsection{Ergodicity}\label{ergodicity}}

We have successfully made our way back to ergodicity. We will try to
illuminate the definition a bit by examples and non-examples.

To reiterate

\begin{defn}{Ergodicity}
For a group $G$, a measurable separable space $S$, and a $G$-invariant measure $\mu$. An action is called ergodic if all $G$-invariant subsets $A\subset S$ are either null or conull. Which means 
$$
\forall g\in G:\ gA = A \quad \Rightarrow \quad \mu(A)=0 \text{ or } \mu(S\setminus A)=0
$$
\end{defn}

definition; explanation of definition; Examples; why the prerequisites
come in, like quasi-invariance; clarify edge cases. summarize by
``complicated orbits'' argument (could use 2.1.7 as example of
complicatedness).
what do we need actually? We have to take a detour into unitary
representations and define the direct integral to make statements about
certain subgroups. These lead to a theorem (Zimmer 2.2.5) about
vanishing matrix coefficients, which we will use to prove the central
theorem in question. This is a great example of the usefulness of
representation theory, where we transform a problem of groups to a
problem of linear algebra. So instead of asking about invariant vectors
of a group action we look at the behavior of matrices.

The way there will lead us through the direct integral, unitary
representations and in particular the representation of
\(\mathbb{R}^n\), {[}{[}todo{]}{]} (I wanna say why, but I'm not sure.)

\hypertarget{the-direct-integral}{%
\section{The Direct Integral}\label{the-direct-integral}}

In simple terms, the direct integral is a way to patch together locally
defined functions into a function on the whole domain. Let us first
consider the simple case where we have global functions on a measure
space \(M\), that takes values in some Hilbert space \(\mathscr{H}\),
\(f:M \rightarrow \mathscr{H}\). The `sensible' space to put these
functions into is the space of square integrable functions on \(M\),
denoted \(L^2(M, \mathscr{H})\). The word `sensible' here is justified
by being again a Hilbert space by integration
\(\langle f, g\rangle = \int_M\langle f(x), g(x)\rangle\).
{[}{[}todo{]}{]} (doesn't mention measurablity)

The next step towards locality is to use two function, by defining
\(L^2(M_1 \sqcup M_2, \mathscr{H}_1 \oplus \mathscr{H}_2)\), where every
function is defined separately on each \(M_i\), and taking values in
\(\mathscr{H}_i\).

{[}{[}todo{]}{]} (show the decomp in the fin dim case to make matrix rep
clear. and say that the intuition works the same later on)

Suppose we have a measure space \(M\), and for each \(x \in M\) a
Hilbert space \(\mathscr{H}_x\) such that \(x \mapsto \mathscr{H}_x\) is
piecewise constant, that is, we have a disjoint decomposition of \(M\)
into \(\cup_{i=1}^{\infty} M_i\) such that for \(x,y \in M_i\),
\(\mathscr{H}_x = \mathscr{H}_y\). {[}{[}todo{]}{]} (fix with info)
Interesting aside: the condition that the assignment
\(x \mapsto \mathscr{H}_x\) be piecewise constant is not necessary. We
can allow the Hilbert spaces to be arbitrary, and in fact uncountably
infinite. Short answer: magic; slightly less short answer: von Neumann.
A \emph{section} on \(M\) is an assignment \(x \mapsto f(x)\), where
\(f(x) \in \mathscr{H}_x\). Since \(\mathscr{H}_x\) is piecewise
constant, the notion of measurability carries over in an obvious manner,
namely that a measurable function on \(M\) is measurable on each \(M_i\)
into the appropriate Hilbert space. Let \(L^2(M, \{\mathscr{H}_x\})\) be
the set of square integrable sections \(\int \| f \|^2 < \infty\) where
we identify two sections if they agree almost everywhere. This set is
then also a Hilbert space with the inner product
\(\langle f | g \rangle = \int_M \langle f(x) | g(x) \rangle\).

Suppose now we have for each \(x \in M\) a unitary representation
\(\pi_x\) of a group \(G\) on \(\mathscr{H}_x\). We say this is
measurable when for \(g \in G\), \(\pi_x(g)\) is a measurable function
on each \(M_i \times G\).

This allows us to define the relevant representation we intermediately
care about.

\hypertarget{unitary-representations}{%
\section{Unitary Representations}\label{unitary-representations}}

{[}{[}todo{]}{]} (un-garbage intro) We need some more information about
irreducible unitary representations to understand the action(s) of
\(SL(n, \mathbb{R})\).

\hypertarget{theorem}{%
\subsection{Theorem}\label{theorem}}

(Zimmer 2.3.3) - For any unitary representation \(\pi\) of
\(\mathbb{R}^n\), there exist \(\mu, \mathscr{H}_{\lambda}\), on
\(\hat{\mathbb{R}}^n\) such that
\(\pi \cong \pi_{\mu, \mathscr{H}_{\lambda}}\). -
\(\pi_{\mu, \mathscr{H}_{\lambda}}\) and
\(\pi_{\mu', \mathscr{H}_{\lambda}'}\) are unitarily equivalent if and
only if - \(\mu \sim \mu'\), i.e., they are in the same measure class
and - \(dim\mathscr{H}_{\lambda} = dim \mathscr{H}_{\lambda}'\) a.e.

\hypertarget{theorem-1}{%
\subsection{Theorem}\label{theorem-1}}

(2.3.5 Proposition Mackey 3) Suppose \(\mathbb{R}^n \subset G\) is a
normal subgroup and \(\pi\) is a unitary representation of \(G\). Write
\(\pi | \mathbb{R}^n \cong \pi_{(\mu, \mathscr{H}_{\lambda})}\) for some
\((\mu, \mathscr{H}_{\lambda})\) by 2.3.3. Then - \(\mu\) is
quasi-invariant under the action of \(G\) on \(\hat{\mathbb{R}}^n\). -
If \(E \subset \mathbb{R}^n\) is measurable, let
\(\mathscr{H}_E = L^2(E, \mu, \{\mathscr{H}_{\lambda}\})\) . Then
\(\pi(g)\mathscr{H}_E = \mathscr{H}_{g \cdot E}\) - If \(\pi\) is
irreducible, then \(\mu\) is ergodic and \(dim\mathscr{H}_{\lambda}\) is
constant on a \(\mu\)-conull set. \#\#\# proof {[}{[}todo{]}{]}

\hypertarget{representation-of-rn}{%
\subsection{Representation of R\^{}n}\label{representation-of-rn}}

{[}{[}todo{]}{]} (this drops out of nowhere) All the irreducible unitary
representations of \(\mathbb{R}^n\) are one-dimensional.

It turns out that the group unitary representations on \(\mathbb{R}^n\)
are isomorphic to \(\mathbb{R}^n\). So we define a map from
\(\mathbb{R}^n\) to \(\mathcal{U}(\mathbb{C})\) and show that it's in
fact bijective. Let \(\theta\). \(t\) be in \(\mathbb{R}^n\) and let
\(\lambda_{\theta}(t) = e^{i\langle \theta | t \rangle}\). This is in
fact a unitary automorphism on \(\mathbb{C}\) by multiplication. To
clarify, for every \(\theta \in \mathbb{R}^n\) we have a representation
given by \[
\begin{align*}
\lambda_{\theta}:\ & \mathbb{R}^n \rightarrow \mathcal{U}(\mathbb{C}) \\
& t \mapsto e^{i \langle \theta | t \rangle}
\end{align*}
\] We denote the group of representations by \(\hat{\mathbb{R}}^n\). It
is in fact a group under pointwise multiplication.

{[}{[}todo{]}{]} (this sort of drops out of nowhere)

This definition is maybe a bit dense, so here is the assignment
formatted in pseudo code. Note here that \(\text{lambda}\) denotes the
programming term of a lambda function, an unfortunate notation
collision. \[
\begin{align*}
& \text{func }\ \pi_{\mu,\mathscr{H}_{\lambda}}(t: \mathbb{R}^n) \rightarrow \mathcal{U}(L^2(\hat{\mathbb{R}}^n)) \ \{ \\
& \qquad \text{return lambda}(f:\ L^2(\hat{\mathbb{R}}^n)) \rightarrow L^2(\hat{\mathbb{R}}^n) \ \{ \\
& \qquad \qquad \text{return lambda}(\lambda:\ \hat{\mathbb{R}}^n) \rightarrow \mathscr{H}_{\lambda} \ \{ \\
& \qquad \qquad \qquad \text{return }\lambda(t)f(\lambda) \\
& \qquad \qquad \} \\
& \qquad \} \\
& \} \\
\end{align*}
\]

\hypertarget{the-connection-between-ergodicity-and-unitary-representations}{%
\subsection{The Connection between Ergodicity and Unitary
Representations}\label{the-connection-between-ergodicity-and-unitary-representations}}

approach: - char func - char func in L2(S) and non-trivial - if A
invariant then char func invariant as a vector in L2(S) - due diligence:
make sure measure works

To see why we care about unitary representations at all if we really
want ergodicity, we neeedd to make the folllowing connection. We use the
characteristic function of a set to connect the set to a vector in
\(L^2(S)\). The characteristic function of a subset \(A\subset S\), is
defined as \(\chi_A(x) = 1\) for \(x \in A\) and \(0\) otherwise.

This representation allows us to pass from talking about sets to talking
about vectors, while retaining the properties we care about.

\begin{thm}
An action $G\curvearrowright S$, with **finite** invariant measure is ergodic on $S$ if and only if the restriction of the above representation to  in $L^2(S) \ominus \mathbb{C}$ has no invariant vectors.
\end{thm}

Since \(S\) has finite measure, assume \(\mu(S) =1\).

\begin{pf}
"$\Leftarrow$": Proof by contrapositive: If $A\subset S$ is $G$-invariant with measure $0 < \mu(A) < \mu(S) = 1$ then $\chi_A$ is also $G$-invariant in $L^2(S)$ as well as the projection $\chi_A - \mu(A)\cdot 1$ in $L^2(S)\ominus \mathbb{C}$.
Therefore there exists an invariant vector in $L^2(S)\ominus \mathbb{C}$.
"$\Rightarrow$": (\cite{Kerr16}(Prop 2.7)) Suppose the action is ergodic and $f\in L^2(S)\ominus \mathbb{C}$ is $G$-invariant.
We can find a measurable set $D\subset \mathbb{C}$ such that $0<\mu(f^{-1}(D)) < 1$ and denote $\widetilde{A} = f^{-1}$. Now we verify ergodicity. For every $g\in G$ the symmetric difference $g\widetilde{A} \Delta \widetilde{A}$, for which all points are in the set $\{x \in X | \ |f(x)-sf(x)| > 0\}$, which has measure zero because $\|f- sf\|_2=0$. Therefore the action fails to be ergodic.
\end{pf}

The adjective ``finite'' on the measure is necessary, because for a set
\(A\) of infinite measure the statement is no longer true as \(\chi_A\)
will no longer be in \(L^2\).

If \(A\subset S\) is \(G\)-invariant then \(\chi_A\in L^2(S)\) will also
be \(G\)-invariant. {[}{[}todo{]}{]} (is ominus actually a valid op
here? yes, see Kerr Li prop 2.7) For \(A\) neither null nor conull then
\(\chi_A\), \(f_A \neq 0\), where \(f_A\) is the projection of
\(\chi_A\) onto \(L^2(S) \ominus \mathbb{C}\).
We start here because it is an easy example of the theorem and a general
group \(G\) has many subgroups locally isomorphic to
\(SL(2, \mathbb{R})\). Later we extend the proof, first to
\(SL(n, \mathbb{R})\) and then to a general \(G\).

To state our intentions: we first show that either the matrix
coefficients vanish as we want, or there exist invariant vectors. Then
we show that there are no invariant vectors, completing the statement.

We're going to use the following decomposition, which we take for
granted {[}{[}todo{]}{]} (find reference for Iwasawa decomposition). The
so called Iwasawa decomposition of \(SL(2, \mathbb{R})\) into three
matrices \(K\), \(A\), and \(N\), defined as \[
\begin{align}
K & =\quad \left\{ \begin{pmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta\end{pmatrix} \subset SL(2, \mathbb{R})  \ | \ \theta \in \mathbb{R} \right\} \\
A & =\quad \left\{ \begin{pmatrix} r & 0 \\ 0 & r^{-1} \end{pmatrix} \subset SL(2, \mathbb{R})  \ | \ r > 0 \right\} \\
N & =\quad \left\{ \begin{pmatrix} 1 & x \\ 0 & 1 \end{pmatrix} \subset SL(2, \mathbb{R})  \ | \ x \in \mathbb{R} \right\}\\
\end{align}
\]

We look at the subgroup
\[P \subset SL(2, \mathbb{R}) = \begin{pmatrix}a & b \\ 0 & a^{-1}\end{pmatrix}\]
of upper triangular matrices. Together with the lower diagonal matrices
\(\bar{P}\), they generate \(SL(2, \mathbb{R})\). To see this, decompose
as follows: \[\begin{pmatrix}1&0\\\alpha&1\end{pmatrix}
\begin{pmatrix}x&0\\0&1/x\end{pmatrix}
\begin{pmatrix}1&\beta\\0&1\end{pmatrix} = 
\begin{pmatrix} x&\beta x\\\alpha x& \alpha\beta x+1/x\end{pmatrix}\]
For any matrix \(A = \begin{pmatrix}a & b \\ c & d\end{pmatrix}\) in
\(SL(2, \mathbb{R})\) with matrix coefficient \(a \neq 0\), we can solve
for \(x,\alpha, \beta\). In the case of \(a = 0\) we can use the
following construction: \[\begin{pmatrix} 1&0\\\alpha&1\end{pmatrix}
\begin{pmatrix} 1&\beta\\0&1\end{pmatrix}
\begin{pmatrix} 1&0\\\gamma&1\end{pmatrix}
\begin{pmatrix} 1&\delta\\0&1\end{pmatrix}=
\begin{pmatrix}
1+\beta\gamma&\delta(1+\beta\gamma)+\beta\\
\alpha(1+\beta\gamma)+\gamma&\alpha\delta(1+\beta\gamma)+\alpha\beta+\gamma\delta+1
\end{pmatrix}\] If \(1 + \beta\gamma = 0\), the above product becomes
\(\begin{pmatrix} 0&\beta\\ \gamma& 1+\alpha\beta+\gamma\delta \end{pmatrix}\)
and we can make suitable choices for \(\alpha, \beta, \gamma, \delta\)
to construct \(A\).

\hypertarget{theorem-for-p}{%
\subsection{Theorem for P}\label{theorem-for-p}}

The upper triangular group can be decomposed into
\[\begin{pmatrix}a & b \\ 0 & a^{-1}\end{pmatrix} =
P = AN =
\begin{pmatrix}a & 0 \\ 0 & a^{-1}\end{pmatrix} \begin{pmatrix}1 & b \\ 0 & 1\end{pmatrix}\]
\#\# Theorem (Zimmer 2.3.6) Let \(\pi\) be a unitary representation of
\(P = AN\). Then either - \(\pi|N\) has a nontrivial invariant vector or
- The matrix coefficients of \(\pi(g)\) as \(g \rightarrow \infty\).

\hypertarget{proof}{%
\subsubsection{proof}\label{proof}}

{[}{[}unoriginal{]}{]} We apply 2.3.5, identifying N \textasciitilde{}
IR. Let n IN = n\textless ll.K ,\textgreater¬∑ If Jl( \{0\})
\textgreater{} 0, then n IN has invariant vectors (namely Jt' 0 ). We
now show that if Jl( \{0\}) = 0, then assertion (ii) in the theorem is
satisfied. To see this, consider the action of P on N. An elementary
calculation shows thatErgodic theory and semisimple groups 28 acts on fJ
\textasciitilde{} IR via multiplication by a 2 ‚Ä¢ Hence, given any
compact subsets E, F c IR- \{0\}, for gEA outside a sufficiently large
compact set we have Jl.(gE n F) = 0. Given any two unit vectors f, hE L
2 (1R, Jl., \{ Jf;.\} ), and e \textgreater{} 0 we can choose compact
subsets E, F c IR- \{0\} such that Then I\textless{} n(g)fl h) I :`¬£ 2e
+ I(n(g)(XEf)I(XF'' h))l. But n(g)(xEf)EJf9 E by 2.3.5 (ii) and by our
above remark, choosing gEA outside a sufficiently large compact subset
of A we can ensure Jf gE .1 Jt' p, and hence that I\textless{} n(g)fl h)
I ;¬£ 2e. This completes the proof of the theorem. Theorem 2.3.6 gives a
vanishing theorem for the matrix coefficients of repre- sentations of P.
In the next section we will see how to use this to prove Moore's
theorem.

\hypertarget{theorem-for-cartan-decomposition}{%
\subsection{Theorem for Cartan
decomposition}\label{theorem-for-cartan-decomposition}}

\hypertarget{polar-decomposition-to-cartan}{%
\subsection{Polar decomposition to
Cartan}\label{polar-decomposition-to-cartan}}

\(T = US\) for some unitary \(U\) and a sym pos def \(S\). \(S\) can be
diagonalized into \(U_0 D U_0^{-1}\) so we can write
\(T = U U_0 D U_0^{-1} = U_1 D U_2\) for \(U_i \in SO(2, \mathbb{R})\).
Then \(SL(2, \mathbb{R}) = KAK\) for \(K = SO_2\) and \(A\) the diagonal
group. This is the Cartan decomposition.

\hypertarget{lemma}{%
\subsection{Lemma}\label{lemma}}

If \(\pi\) is a unitary representation of a Group \(G\) and we can write
\(G = KAK\), then it suffices to check that the matrix coefficients
vanish on A as \(g \rightarrow \infty\).

\hypertarget{proof-1}{%
\subsubsection{proof}\label{proof-1}}

The proof works by observing that \(K\) is compact, and so the only part
of G that can go to infinity is \(A\). We take vectors \(v, w\) and
write \(g \in G\) as \(g = k_1 a k_2\). Then the corresponding matrix
coefficient can be written as
\(\langle \pi(g)v|w \rangle = \langle \pi(a) \pi(k_2) v | \pi(k_1)^{-1} w \rangle\).
Since \(g \rightarrow \infty\) we can find a sequence
\(g_n = k_{1,n} g_{n} k_{2,n} \rightarrow \infty\) as
\(n \rightarrow \infty\) with
\(|\langle \pi(g_n) v | w \rangle | \geq \varepsilon\) for some
\(\varepsilon > 0\). Suppose \(k_{1,n} \rightarrow k\) and
\(k_{2,n}^{-1} \rightarrow k'\), then for n sufficiently large n
\(|\langle \pi(a_n)\pi(k)v | \pi(k') w \rangle | \geq \varepsilon/2\).
But since \(K\) is compact and \(g_n \rightarrow \infty\), we must have
\(a_n \rightarrow \infty\). This shows that the must be a matrix
coefficient in \(\pi | A\) that fails to vanish at infinity.

\hypertarget{theorem-for-sl2-r-this-time}{%
\subsection{Theorem for SL(2, R) this
time}\label{theorem-for-sl2-r-this-time}}

If \(\pi\) is a unitary representation of \(G = SL(2, \mathbb{R})\) with
no invariant vectors, then all matrix coefficients of \(\pi\) vanish at
\(\infty\).

\hypertarget{proof-2}{%
\subsubsection{proof}\label{proof-2}}

{[}{[}unoriginal{]}{]} {[}{[}create images for{]}{]} orbits Proof: By
the preceding lemma, it suffices to see that the matrix coefficients
vanish at infinity along A and by Theorem 2.3.6, it suffices to see that
there are no N invariant vectors. Suppose to the contrary that v =f.~0
is N-invariant. Let f(g) = (n(g)vlv). Thenfis continuous and
hi-invariant under N, i.e.,f lifts from a continuous N-invariant
function on G/N. Now N is exactly the stabilizer of a vector (namely (1,
0)) in IR 2 under the natural SL(2, IR) action. Thus, we can identify
G/N with IR 2 - \{0\}. The action of Non G/N is therefore identified
with the action on IR 2 - \{0\} given by ordinary matrix multiplication.
Thus there are two types of orbits, namely all horizontal lines except
the x-axis, and each point on the x-axis (except the origin, of course).
Clearly any continuous function on IR 2 - \{0\} \textasciitilde{} G/N
which is constant along these orbits must actually be constant on the
x-axis. But the x-axis is identified with P/N c G/N under the
identification of G/N with IR 2 - \{0\}. Hencef(g) is constant on P.
However, since n is unitary, if f(g) = (n(g)vlv) is constant on P, it
follows that v must be P-invariant. Therefore f is actually hi-invariant
under P. But P has a dense orbit in GjP. (For example, identify G/P with
projective space of IR 2 under ordinary matrix multiplication.) Thusfis
actually a constant function, and as above, this implies that v is
G-invariant. We are now ready to prove 2.2.20.
{[}{[}unoriginal{]}{]} Following our remark in the preface, we shall
prove this in detail for G = SL(n, IR), and then indicate how the proof
carries over to general G. Let A c SL(n, IR) be the group of diagonal
matrices. We denote an element aEA by (at, \ldots{} , an), where these
are to be interpreted as the diagonal elements of a matrix. We note Ila;
= 1. Let B be the set of matrices (cii) with cu = 1, and cii = 0 fori
=f.~j and i \textasciitilde{} 2. We denote an element bEB by b = (1, b 2
, ‚Ä¢.‚Ä¢ , bn) where this is to be interpreted as the first row of the
corresponding matrix. Then30 Ergodic theory and semisimple groups aBa- 1
= B for aEA, and hence H = AB is a subgroup of G, and B c H is normal.
We observe B \textasciitilde{} IRn- 1 . As with SL(2, IR), by Lemma
2.4.1, it suffices to show that the matrix coefficients of n: IA vanish
at oo. For SL(2, IR) we obtained this using knowledge of the
representation of P. In our more general situation, we will examine the
representation of H. (Note that H = P for n = 2.) Express n: IB
\textasciitilde{} n:\textless\textasciitilde.x .) (by 2.3.3) via the
above identification of B with IRn- 1 . Matrix multiplication shows that
for aEA, bEB, aba- 1 = (1, a 1 ai 1 b2, \ldots{} , a 1 a;; 1 bn)EB. The
adjoint action on !Rn- 1 will be given by the same expression, replacing
b; by the dual variables h i = 2, \ldots{} , n.~Therefore, if E, F c
!Rn- 1 are compact subsets which are disjoint from the union of the
hyperplanes ).; = 0, i = 2, \ldots{} , n then for aEA outside a
sufficiently large compact set, we have a¬∑ En F = 0. Therefore, arguing
exactly as in the proof of Theorem 2.3.6, we deduce that if f.J. assigns
measure 0 to the union of the hyperplanes A.; = 0, then all matrix
coefficients vanish along A, and by our comments above, this suffices to
prove the theorem. Therefore, it remains to show that f.J.(\{A.; = 0\})
\textgreater{} 0 is impossible. If f.J.(\{J.; = 0\}) \textgreater{} 0,
then by definition of f.J.\textless{} 11 .x,J, the subgroup B; c B, B; =
\{bEBibi = 0 fori \#j\} leaves non-trivial vectors invariant (namely,
the subspace .\#p.;=o 1.) However B; c H; c G where H; \textasciitilde{}
SL(2, IR) and is defined as follows H; = \{(cik)ESL(n, IR)Icjj = 1 for j
\# 1, i, and for j \# k and \{1, i\} \# \{j, k\}, Cjk = 0\}. From the
vanishing of matrix coefficients for SL(2, IR), (2.4.2), the existence
of a B;-invariant vector implies the existence of a H;-invariant vector
(since B; is clearly non-compact). In particular, A;= H; n A has
non-trivial invariant vectors. Let W= \{vEYl'ln:(a)v =
vforallaEA;\}.Itsufficestoshowthat WisG-invariant. For then the
representation n:w ofG on Whas kernel (n:w) ::::J A; which by simplicity
of G implies that kernel(n:w) = G, so that G itself leaves all vectors
in W fixed, contradicting our assumptions. (For the analogous argument
in the semisimple case the fact that dim(kernel n:w) \textgreater{} 0
contradicts the assumption that no simple factor of G leaves vectors
invariant.) We now turn to G-invariance of W. For k \# j, let Bki c G be
the one- dimensional subgroup defined by Bki = \{(c,.)lc,, = 1, and for
r \#sand (r, s) \# (k, j), c,. = 0\}. We consider two possibilities. (i)
k \# i or 1 andj \# i or 1. Then Bki commutes with A;, and hence Bki
leaves W invariant. (ii) If \{ k, j\} n \{ i, 1\} \# 0 then A;
normalizes Bki¬∑ Hence A;Bki is a 2-dimensional subgroup and is
isomorphic to P in such a way that A;+-+(diagonal matricesMoore's
ergodicity theorem 31 in P), Bki- N. By Corollary 2.3.7, all
A;-invariant vectors are also Bki invariant. Hence in this case, too,
Bki leaves W invariant. Finally, we remark that since A; c A, A abelian,
A also leaves W invariant. However, A and all Bki together generate G.
Therefore G leaves W invariant, completing the proof.
{[}{[}unoriginal{]}{]} In concluding this section, we indicate the
modifications necessary in the above argument for a general semisimple
G. Let A c G be a maximal IR-split torus. Then A c G' c G where G' is
semisimple and split over IR, and A is the maximal IR-split torus of G'.
Choose a maximal linearly independent set S of positive roots of G'
relative to A such that for a, \{3ES, a+ \{3 is not a root. Then the
direct sum of the root spaces is the Lie algebra of an abelian subgroup
B c G', with dim B =dim A, and B is normalized by A. The representations
of AB can be analyzed exactly as in the case of SL(n, IR), and since the
relevant copies of s1(2, IR) are present, we deduce that either we are
done, or some one-dimensional subgroup A 0 c A leaves a non-trivial
vector fixed. (Actually to obtain this we may need to use the universal
covering G of SL(2, IR) rather than SL(2, IR) itself. Namely, we need
that for N c SL(2, IR) as in the proof of2.4.2, N c G the connected
component of the lift of N to G (so that N \textasciitilde{} N ), that N
invariant vectors are G-invariant. However, this follows by elementary
covering space arguments applied to the picture in the proof of 2.4.2.
If G is algebraic, which will be our main concern, consideration of
SL(2, IR) suffices.) The proof then proceeds as in the case of SL(n,
IR); G is generated by elements that either commute with Ao or lie in a
suitable copy of the group P.

\hypertarget{return-of-the-initial-example}{%
\subsection{return of the initial
example}\label{return-of-the-initial-example}}

circle back to fractional linear transforms.
hyperbolas! 3 cases comp eucl and non-comp. if we want to go to infinity
and don't want boring examples, hyperbolic geometry is necessary.
fractional linear transforms. riemann sphere model?

\printbibliography

\end{document}
